volumes:
  # metadata_data: {}
  middle_var: {}
  historical_var: {}
  broker_var: {}
  coordinator_var: {}
  router_var: {}
  druid_shared: {}
  metadata_data: {}

services:

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    restart: unless-stopped
    ports:
      - 9092:9092
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

  spark:
    image: apache/spark:3.5.1-scala2.12-java11-python3-ubuntu
    container_name: spark
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"
      - "8080:8080"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master

  # Spark Worker
  worker:
    image: apache/spark:3.5.1-scala2.12-java11-python3-ubuntu
    container_name: worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
    depends_on:
      - spark
    ports:
      - "8084:8084"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark:7077

  # Database for druid
  postgres:
    container_name: postgres
    image: postgres:latest
    restart: unless-stopped
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=FoolishPassword
      - POSTGRES_USER=druid
      - POSTGRES_DB=druid
    volumes:
      - ./postgres-init:/docker-entrypoint-initdb.d
    command: ["postgres", "-c", "max_connections=300"]

  # Druid Cordinator
  coordinator:
    image: apache/druid:33.0.0
    container_name: coordinator
    restart: unless-stopped
    volumes:
      - druid_shared:/opt/shared
      - coordinator_var:/opt/druid/var
    ports:
      - "8081:8081"
    command:
      - coordinator
    depends_on:
      - zookeeper
      - postgres
    env_file:
      - ./app_druid/environment.env

  # Druid Broker
  broker:
    image: apache/druid:33.0.0
    container_name: broker
    restart: unless-stopped
    volumes:
      - broker_var:/opt/druid/var
    ports:
      - "8082:8082"
    command:
      - broker
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
       - ./app_druid/environment.env

  # Druid Historical
  historical:
    image: apache/druid:33.0.0
    container_name: historical
    restart: unless-stopped
    volumes:
      - druid_shared:/opt/shared
      - historical_var:/opt/druid/var
    ports:
      - "8083:8083"
    command:
      - historical
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
      - ./app_druid/environment.env

  # Druid middlemanager
  middlemanager:
    image: apache/druid:33.0.0
    container_name: middlemanager
    volumes:
      - druid_shared:/opt/shared
      - middle_var:/opt/druid/var
    ports:
      - "8091:8091"
      - "8100-8105:8100-8105"
    command:
      - middleManager
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
      - ./app_druid/environment.env
  
  # Druid router
  router:
    image: apache/druid:33.0.0
    container_name: router
    restart: unless-stopped
    volumes:
      - router_var:/opt/druid/var
    ports:
      - "8888:8888"
    command:
      - router
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
      - broker
      - historical
    env_file:
      - ./app_druid/environment.env

  # Superset need to change the password and username on production
  superset:
    build: 
      context: ./app_superset
      dockerfile: ./Dockerfile
    container_name: superset
    restart: unless-stopped
    ports:
      - 8088:8088
    environment:
      - SUPERSET_SECRET_KEY=EIxAG2O3Mi9DaOsAXgSDRrpe/c4/LiuEBi6xBaEf5FcYQ0s8XdkqlOIK
    command: >
      /bin/sh -c "
        superset db upgrade &&
        superset fab create-admin --username admin --firstname Admin --lastname User --email admin@example.com --password admin &&
        superset init &&
        superset run -h 0.0.0.0 -p 8088"

  # Airflow sequency need change to celery on product
  airflow:
    build: 
      context: ./app_airflow
      dockerfile: ./Dockerfile
    container_name: airflow
    restart: unless-stopped
    depends_on:
      - kafka
      - redis
    volumes:
      - ./app_airflow/app/:/airflow/
    environment:
      - AIRFLOW_HOME=/airflow
      - AIRFLOW_UID=50000
      - AIRFLOW__API_AUTH__JWT_SECRET=R29rGMav62+uPLzRhcpIYo607eAjM0Xm5cc4RNmJ6AM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    ports:
      - 3000:8080
    command: airflow standalone
  
  # Redis for Airflow
  redis:
    image: redis
    container_name: redis
    restart: unless-stopped
    volumes:
      - ./a-redis:/data

  # OpenMetadata service
  openmetadata:
    image: openmetadata/server:1.4.0
    container_name: openmetadata
    restart: unless-stopped
    environment:
      - OPENMETADATA_HOST=http://openmetadata:8585
      - OPENMETADATA_DATABASE_HOST=postgres
      - OPENMETADATA_DATABASE_USER=druid
      - OPENMETADATA_DATABASE_PASSWORD=FoolishPassword
      - OPENMETADATA_DATABASE_NAME=openmetadata_db
      - AIRFLOW_HOST=http://airflow:8080
    ports:
      - "8585:8585"
    depends_on:
      - postgres
      - airflow
    volumes:
      - metadata_data:/opt/openmetadata/data
      
  # OpenMetadata Ingestion Service
  ingestion:
    image: openmetadata/ingestion:1.4.0
    container_name: openmetadata_ingestion
    restart: unless-stopped
    depends_on:
      - openmetadata
      - airflow
    environment:
      - OPENMETADATA_PROTOCOL=http
      - OPENMETADATA_HOST=openmetadata
      - OPENMETADATA_PORT=8585
    volumes:
      - metadata_data:/opt/openmetadata/data